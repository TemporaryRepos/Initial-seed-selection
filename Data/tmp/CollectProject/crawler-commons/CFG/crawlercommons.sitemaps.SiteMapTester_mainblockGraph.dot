digraph "unitGraph" {
    "Block 0:
[preds: ] [succs: 1 2 ]
r0 := @parameter0: java.lang.String[];
$i0 = lengthof r0;
if $i0 >= 1 goto $r1 = new java.net.URL;
"
    "Block 1:
[preds: 0 ] [succs: 6 ]
$r5 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r5.<org.slf4j.Logger: void error(java.lang.String)>(\"Fetch and process a sitemap (recursively if a sitemap index)\");
$r6 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r6.<org.slf4j.Logger: void error(java.lang.String)>(\"Usage: SiteMapTester <URL_TO_TEST> [MIME_TYPE]\");
$r7 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r7.<org.slf4j.Logger: void error(java.lang.String)>(\"Options:\");
$r8 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r8.<org.slf4j.Logger: void error(java.lang.String)>(\"  URL_TO_TEST  URL of sitemap\");
$r9 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r9.<org.slf4j.Logger: void error(java.lang.String)>(\"  MIME_TYPE    force processing sitemap as MIME type,\");
$r10 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r10.<org.slf4j.Logger: void error(java.lang.String)>(\"               bypass automatic MIME type detection\");
$r11 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r11.<org.slf4j.Logger: void error(java.lang.String)>(\"Java properties:\");
$r12 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r12.<org.slf4j.Logger: void error(java.lang.String)>(\"  sitemap.strictNamespace\");
$r13 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r13.<org.slf4j.Logger: void error(java.lang.String)>(\"                  if true sitemaps are required to use the standard namespace URI\");
$r14 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r14.<org.slf4j.Logger: void error(java.lang.String)>(\"  sitemap.allow.dtd\");
$r15 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r15.<org.slf4j.Logger: void error(java.lang.String)>(\"                  if true sitemaps are allowed to include a DTD\");
$r16 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r16.<org.slf4j.Logger: void error(java.lang.String)>(\"  sitemap.extensions\");
$r17 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r17.<org.slf4j.Logger: void error(java.lang.String)>(\"                  if true enable sitemap extension parsing\");
$r18 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r18.<org.slf4j.Logger: void error(java.lang.String)>(\"  sitemap.filter.urls\");
$r19 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r19.<org.slf4j.Logger: void error(java.lang.String)>(\"                  if true filter and normalize all URLs found in the sitemap\");
$r20 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r20.<org.slf4j.Logger: void error(java.lang.String)>(\"                  using crawlercommons.filters.basic.BasicURLNormalizer\");
goto [?= return];
"
    "Block 2:
[preds: 0 ] [succs: 3 4 ]
$r1 = new java.net.URL;
$r2 = r0[0];
specialinvoke $r1.<java.net.URL: void <init>(java.lang.String)>($r2);
r3 = $r1;
$i1 = lengthof r0;
if $i1 <= 1 goto $r21 = null;
"
    "Block 3:
[preds: 2 ] [succs: 5 ]
$r21 = r0[1];
goto [?= r4 = $r21];
"
    "Block 4:
[preds: 2 ] [succs: 5 ]
$r21 = null;
"
    "Block 5:
[preds: 3 4 ] [succs: 6 ]
r4 = $r21;
staticinvoke <crawlercommons.sitemaps.SiteMapTester: void parse(java.net.URL,java.lang.String)>(r3, r4);
"
    "Block 6:
[preds: 1 5 ] [succs: ]
return;
"
    "Block 0:
[preds: ] [succs: 1 2 ]
r0 := @parameter0: java.lang.String[];
$i0 = lengthof r0;
if $i0 >= 1 goto $r1 = new java.net.URL;
"->"Block 1:
[preds: 0 ] [succs: 6 ]
$r5 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r5.<org.slf4j.Logger: void error(java.lang.String)>(\"Fetch and process a sitemap (recursively if a sitemap index)\");
$r6 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r6.<org.slf4j.Logger: void error(java.lang.String)>(\"Usage: SiteMapTester <URL_TO_TEST> [MIME_TYPE]\");
$r7 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r7.<org.slf4j.Logger: void error(java.lang.String)>(\"Options:\");
$r8 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r8.<org.slf4j.Logger: void error(java.lang.String)>(\"  URL_TO_TEST  URL of sitemap\");
$r9 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r9.<org.slf4j.Logger: void error(java.lang.String)>(\"  MIME_TYPE    force processing sitemap as MIME type,\");
$r10 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r10.<org.slf4j.Logger: void error(java.lang.String)>(\"               bypass automatic MIME type detection\");
$r11 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r11.<org.slf4j.Logger: void error(java.lang.String)>(\"Java properties:\");
$r12 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r12.<org.slf4j.Logger: void error(java.lang.String)>(\"  sitemap.strictNamespace\");
$r13 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r13.<org.slf4j.Logger: void error(java.lang.String)>(\"                  if true sitemaps are required to use the standard namespace URI\");
$r14 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r14.<org.slf4j.Logger: void error(java.lang.String)>(\"  sitemap.allow.dtd\");
$r15 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r15.<org.slf4j.Logger: void error(java.lang.String)>(\"                  if true sitemaps are allowed to include a DTD\");
$r16 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r16.<org.slf4j.Logger: void error(java.lang.String)>(\"  sitemap.extensions\");
$r17 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r17.<org.slf4j.Logger: void error(java.lang.String)>(\"                  if true enable sitemap extension parsing\");
$r18 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r18.<org.slf4j.Logger: void error(java.lang.String)>(\"  sitemap.filter.urls\");
$r19 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r19.<org.slf4j.Logger: void error(java.lang.String)>(\"                  if true filter and normalize all URLs found in the sitemap\");
$r20 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r20.<org.slf4j.Logger: void error(java.lang.String)>(\"                  using crawlercommons.filters.basic.BasicURLNormalizer\");
goto [?= return];
";
    "Block 0:
[preds: ] [succs: 1 2 ]
r0 := @parameter0: java.lang.String[];
$i0 = lengthof r0;
if $i0 >= 1 goto $r1 = new java.net.URL;
"->"Block 2:
[preds: 0 ] [succs: 3 4 ]
$r1 = new java.net.URL;
$r2 = r0[0];
specialinvoke $r1.<java.net.URL: void <init>(java.lang.String)>($r2);
r3 = $r1;
$i1 = lengthof r0;
if $i1 <= 1 goto $r21 = null;
";
    "Block 1:
[preds: 0 ] [succs: 6 ]
$r5 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r5.<org.slf4j.Logger: void error(java.lang.String)>(\"Fetch and process a sitemap (recursively if a sitemap index)\");
$r6 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r6.<org.slf4j.Logger: void error(java.lang.String)>(\"Usage: SiteMapTester <URL_TO_TEST> [MIME_TYPE]\");
$r7 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r7.<org.slf4j.Logger: void error(java.lang.String)>(\"Options:\");
$r8 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r8.<org.slf4j.Logger: void error(java.lang.String)>(\"  URL_TO_TEST  URL of sitemap\");
$r9 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r9.<org.slf4j.Logger: void error(java.lang.String)>(\"  MIME_TYPE    force processing sitemap as MIME type,\");
$r10 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r10.<org.slf4j.Logger: void error(java.lang.String)>(\"               bypass automatic MIME type detection\");
$r11 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r11.<org.slf4j.Logger: void error(java.lang.String)>(\"Java properties:\");
$r12 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r12.<org.slf4j.Logger: void error(java.lang.String)>(\"  sitemap.strictNamespace\");
$r13 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r13.<org.slf4j.Logger: void error(java.lang.String)>(\"                  if true sitemaps are required to use the standard namespace URI\");
$r14 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r14.<org.slf4j.Logger: void error(java.lang.String)>(\"  sitemap.allow.dtd\");
$r15 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r15.<org.slf4j.Logger: void error(java.lang.String)>(\"                  if true sitemaps are allowed to include a DTD\");
$r16 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r16.<org.slf4j.Logger: void error(java.lang.String)>(\"  sitemap.extensions\");
$r17 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r17.<org.slf4j.Logger: void error(java.lang.String)>(\"                  if true enable sitemap extension parsing\");
$r18 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r18.<org.slf4j.Logger: void error(java.lang.String)>(\"  sitemap.filter.urls\");
$r19 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r19.<org.slf4j.Logger: void error(java.lang.String)>(\"                  if true filter and normalize all URLs found in the sitemap\");
$r20 = <crawlercommons.sitemaps.SiteMapTester: org.slf4j.Logger LOG>;
interfaceinvoke $r20.<org.slf4j.Logger: void error(java.lang.String)>(\"                  using crawlercommons.filters.basic.BasicURLNormalizer\");
goto [?= return];
"->"Block 6:
[preds: 1 5 ] [succs: ]
return;
";
    "Block 2:
[preds: 0 ] [succs: 3 4 ]
$r1 = new java.net.URL;
$r2 = r0[0];
specialinvoke $r1.<java.net.URL: void <init>(java.lang.String)>($r2);
r3 = $r1;
$i1 = lengthof r0;
if $i1 <= 1 goto $r21 = null;
"->"Block 3:
[preds: 2 ] [succs: 5 ]
$r21 = r0[1];
goto [?= r4 = $r21];
";
    "Block 2:
[preds: 0 ] [succs: 3 4 ]
$r1 = new java.net.URL;
$r2 = r0[0];
specialinvoke $r1.<java.net.URL: void <init>(java.lang.String)>($r2);
r3 = $r1;
$i1 = lengthof r0;
if $i1 <= 1 goto $r21 = null;
"->"Block 4:
[preds: 2 ] [succs: 5 ]
$r21 = null;
";
    "Block 3:
[preds: 2 ] [succs: 5 ]
$r21 = r0[1];
goto [?= r4 = $r21];
"->"Block 5:
[preds: 3 4 ] [succs: 6 ]
r4 = $r21;
staticinvoke <crawlercommons.sitemaps.SiteMapTester: void parse(java.net.URL,java.lang.String)>(r3, r4);
";
    "Block 4:
[preds: 2 ] [succs: 5 ]
$r21 = null;
"->"Block 5:
[preds: 3 4 ] [succs: 6 ]
r4 = $r21;
staticinvoke <crawlercommons.sitemaps.SiteMapTester: void parse(java.net.URL,java.lang.String)>(r3, r4);
";
    "Block 5:
[preds: 3 4 ] [succs: 6 ]
r4 = $r21;
staticinvoke <crawlercommons.sitemaps.SiteMapTester: void parse(java.net.URL,java.lang.String)>(r3, r4);
"->"Block 6:
[preds: 1 5 ] [succs: ]
return;
";
}
